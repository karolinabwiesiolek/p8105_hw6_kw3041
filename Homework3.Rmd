---
title: "Homework3_kw3041"
output: html_document
date: "2025-12-03"
---

## PROBLEM 1 

```{r}
getwd()
list.files()
list.files("data")

```

```{r}
homicide_df =
  readr::read_csv("/Users/karolinawiesiolek/Desktop/Data_Science/Homework3/homicide-data.csv") |>
  janitor::clean_names()

```

Loading in and cleaning the data: 

```{r}
### Problem 1

library(tidyverse)
library(janitor)
library(broom)
library(purrr)
library(forcats)

homicide_df =
  read_csv("/Users/karolinawiesiolek/Desktop/Data_Science/Homework3/homicide-data.csv") |>
  clean_names() |>
  mutate(
    # Create "City, ST" variable
    city_state = str_c(city, ", ", state),
    
    # Binary outcome: 1 = solved, 0 = not solved
    solved = if_else(disposition == "Closed by arrest", 1, 0),
    
    # Make sure age is numeric
    victim_age = as.numeric(victim_age),
    
    # Clean race and sex
    victim_race = str_to_lower(victim_race),
    victim_sex  = factor(victim_sex)
  ) |>
  # Drop cities with missing race reporting or wrong Tulsa
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")
  ) |>
  # Only white / black victims
  filter(victim_race %in% c("white", "black"))

```

Began by importing the Washington Post homicide dataset and standardizing variable names.
A new variable, city_state, was created by pasting together the city and state fields (e.g., “Baltimore, MD”), which serves as the grouping variable for later analyses. Then, a binary indicator of whether a homicide was solved was constructed:
  + 1 = “Closed by arrest”
  + 0 = all other dispositions

This converts the outcome into a form appropriate for logistic regression.

I converted victim_age to numeric, which introduced some NA values.
This is expected because the original dataset contains entries such as "Unknown".
These cases are automatically removed during model fitting.

Following the assignment instructions, we omitted cities:
   + Dallas, TX
   + Phoenix, AZ
   + Kansas City, MO
   + Tulsa, AL

These cities either do not report victim race or are known data entry errors. I restricted the analysis to homicides where the victim's race is recorded as white or black, because these are the groups with the most complete and consistent reporting across cities.


```{r}
# Filter to Baltimore
baltimore_df =
  homicide_df |>
  filter(city_state == "Baltimore, MD")

# Fit logistic regression: solved ~ age + sex + race
baltimore_fit =
  glm(
    solved ~ victim_age + victim_sex + victim_race,
    data = baltimore_df,
    family = binomial()
  )

# Tidy, exponentiate to get odds ratios + CIs
baltimore_results =
  baltimore_fit |>
  tidy(conf.int = TRUE, exponentiate = TRUE)

# Adjusted OR for male vs female victims
baltimore_or_male =
  baltimore_results |>
  filter(term == "victim_sexMale") |>
  select(term, estimate, conf.low, conf.high)

baltimore_or_male

```

Commentary: Baltimore Logistic Regression
I fit a logistic regression model predicting whether a homicide in Baltimore, MD was solved, using victim age, victim sex, and victim race as predictors. The resulting adjusted odds ratio (OR) comparing male to female victims is:
  + OR = 0.426
  + 95% CI: 0.324 to 0.558

Because the OR is well below 1, this indicates that, after adjusting for race and age, homicides involving male victims were significantly less likely to be solved compared to those involving female victims in Baltimore.

The confidence interval does not include 1, suggesting that this association is statistically strong. Substantively, this means that sex differences in case resolution are pronounced in Baltimore even after accounting for racial and age differences.

```{r}
city_or_df =
  homicide_df |>
  nest(data = -city_state) |>
  mutate(
    # fit model in each city
    fit = map(
      data,
      ~ glm(
        solved ~ victim_age + victim_sex + victim_race,
        data = .x,
        family = binomial()
      )
    ),
    # tidy model output, exponentiate to get odds ratios
    results = map(
      fit,
      ~ tidy(.x, conf.int = TRUE, exponentiate = TRUE)
    )
  ) |>
  select(city_state, results) |>
  unnest(results) |>
  # keep only male vs female coefficient
  filter(term == "victim_sexMale") |>
  # reorder by OR for plotting
  mutate(
    city_state = fct_reorder(city_state, estimate)
  )

city_or_df

```

Commentary: Tidy Pipeline for All Cities

To generalize the analysis beyond Baltimore, I used a tidy, map-based workflow to fit the same logistic regression model to each city in the dataset. For each city, I extracted the adjusted odds ratio comparing male and female victims.

This highlights notable variability in the sex–resolution relationship across cities. Many cities show ORs below 1, similar to Baltimore, meaning male-victim cases tend to be less likely to be solved. Some cities have ORs close to 1, indicating little or no sex-related difference in case resolution. A smaller number of cities have ORs above 1, where cases with male victims appear more likely to be solved.

Warnings such as “fitted probabilities numerically 0 or 1 occurred” are common in logistic regression, especially when cities have small sample sizes or complete separation (e.g., if nearly all cases for one sex are solved or unsolved). These do not invalidate the results but indicate higher uncertainty for those cities.

Because each model was adjusted for age and race, the ORs represent sex differences independent of demographic composition in each city.

```{r}
ggplot(city_or_df, aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  coord_flip() +
  labs(
    x = "City",
    y = "Adjusted odds ratio (male vs female, solved)",
    title = "Adjusted odds of homicide being solved for male vs female victims by city"
  )

```


Commentary: Interpretation of the Odds Ratio Plot

The plot displays adjusted odds ratios and confidence intervals for all cities, sorted from lowest to highest OR. Patterns emerge:

1. Substantial variation across cities:
The association between victim sex and homicide resolution is not uniform. Some cities show strong disadvantages for male victims (OR < 1), while others show near-no difference or even a slight advantage (OR > 1).

2. Most cities center below OR = 1:
This suggests that in the majority of cities, homicides involving male victims are less likely to be solved than those involving female victims, after adjusting for race and age.

3. Wide confidence intervals in some cities:
Cities with few homicides, or little variation in whether cases are solved, produce unstable estimates. These wide intervals often overlap 1, indicating high uncertainty.

4. Clear outliers:
Cities like Baltimore and Chicago show particularly strong effects (ORs well below 1), meaning male-victim cases are markedly less likely to be cleared.


## PROBLEM 2 


```{r}
library(p8105.datasets)
data("weather_df")

weather_clean =
  weather_df |>
  drop_na(tmax, tmin, prcp)
```

```{r}
set.seed(123)

# Function that fits model and returns r^2 and beta1*beta2
boot_fn = function(df) {
  fit = lm(tmax ~ tmin + prcp, data = df)
  
  # Extract r^2
  r2 = broom::glance(fit)$r.squared
  
  # Extract slope estimates
  coefs = broom::tidy(fit)
  beta1 = coefs$estimate[coefs$term == "tmin"]
  beta2 = coefs$estimate[coefs$term == "prcp"]
  
  tibble(
    r2 = r2,
    beta1_beta2 = beta1 * beta2
  )
}

```

Bootstrap function 
```{r}
set.seed(123)

# Function that fits model and returns r^2 and beta1*beta2
boot_fn = function(df) {
  fit = lm(tmax ~ tmin + prcp, data = df)
  
  # Extract r^2
  r2 = broom::glance(fit)$r.squared
  
  # Extract slope estimates
  coefs = broom::tidy(fit)
  beta1 = coefs$estimate[coefs$term == "tmin"]
  beta2 = coefs$estimate[coefs$term == "prcp"]
  
  tibble(
    r2 = r2,
    beta1_beta2 = beta1 * beta2
  )
}

```

500 bootstrap samples :
```{r}
set.seed(1)

boot_results =
  weather_clean |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    estimates = map(strap, boot_fn)
  ) |>
  unnest(estimates)

```

Plot distrubution
```{r}
library(ggplot2)

p_r2 =
  ggplot(boot_results, aes(x = r2)) +
  geom_histogram(bins = 30, fill = "skyblue") +
  labs(title = "Bootstrap Distribution of R-squared")

p_beta =
  ggplot(boot_results, aes(x = beta1_beta2)) +
  geom_histogram(bins = 30, fill = "lightgreen") +
  labs(title = "Bootstrap Distribution of β1 * β2")

p_r2
p_beta

```


95% interval:
```{r}
r2_ci =
  boot_results |>
  summarize(
    lower = quantile(r2, 0.025),
    upper = quantile(r2, 0.975)
  )

beta_ci =
  boot_results |>
  summarize(
    lower = quantile(beta1_beta2, 0.025),
    upper = quantile(beta1_beta2, 0.975)
  )

r2_ci
beta_ci

```

# Commentary 1. Bootstrap Approach Explanation, procedure: 

The goal of this problem is to understand the sampling variability of two statistics from a linear model predicting tmax from tmin and prcp:
  1. the coefficient of determination 
  2. the product of the estimated slopes for tmin and prcp

Because neither statistic has a simple theoretical sampling distribution, I used a bootstrap approach with 5000 resamples of the original dataset. For each bootstrap sample, I refit the linear model and stored the two quantities of interest. This results in empirical distributions that approximate the sampling distributions of these statistics.

# Commentary 2. Distribution of Bootstrap Estimates
The bootstrap histogram of the coefficient of determination is unimodal and tightly concentrated, indicating that the model’s explanatory power is stable across resamples. The distribution has fairly low spread, suggesting that the estimated R² is precise and does not vary dramatically with sampling fluctuations.

In contrast, the distribution of the product of the estimated slopes for tmin and prcp shows more variability and is noticeably more skewed.

Since this statistic is the product of two slope estimates, it naturally inherits more instability, especially because the precipitation effect (β₂) is small and sometimes close to zero.
This results in a distribution that is wider and more asymmetric than the distribution of R².

# Commentary 3. Confidence Interval 
Using the 2.5% and 97.5% quantiles of the bootstrap distributions, I obtained 95% empirical confidence interval of:

  1. 0.934 0.947 for R²
  2. B1B2 interval was: -0.00821 -0.00377

The R² interval is narrow, reinforcing that the model consistently explains a similar proportion of variance across samples.
The interval for B1B2 is wider and spans values near zero, reflecting higher sampling variability and the relatively weak effect of precipitation in the model.

## PROBLEM 3 

